
\documentclass{article}
% \usepackage[sc]{mathpazo}
% \usepackage[T1]{fontenc}
\usepackage{geometry}
\usepackage{amsmath, amssymb, mathtools }
\usepackage{enumerate}
\usepackage{array}
\usepackage{fancyhdr}
\usepackage{verbatim}
\usepackage{color}
\usepackage{pstricks}
% \usepackage{longtable}
% \usepackage{fancyvrb}
% \usepackage{fancyhdr}
\usepackage{eqnarray}
%\pagestyle{fancy}
\usepackage{psfrag}
\usepackage{epsfig,epsf}
\usepackage{pstricks}
\geometry{verbose,tmargin=2.5cm,bmargin=2.5cm,lmargin=2.5cm,rmargin=2.5cm}
\setcounter{secnumdepth}{2}
\setcounter{tocdepth}{2}
\usepackage{url}
\usepackage[unicode=true,pdfusetitle,
            bookmarks=true,bookmarksnumbered=true,bookmarksopen=true,bookmarksopenlevel=2,
            breaklinks=false,pdfborder={0 0 1},backref=false,colorlinks=false]
{hyperref}
\hypersetup{
  pdfstartview={XYZ null null 1}}
\usepackage{breakurl}
\begin{document}

<<setup, include=FALSE, cache=FALSE>>=
  # set global chunk options
opts_chunk$set(fig.path='figure/minimal-', fig.align='center', fig.show='hold')
options(replace.assign=TRUE,width=85)
set.seed(20140423)
@

\title{Final STAT544 Spring2014}

\author{Yet Tien Nguyen}

\maketitle

\section{Description of the data}

The data we will analyze is RNA-Seq data from RFI (Residual Feed Intake) project
from animal science research group. The data consists of a count table with ten thousand rows and 24 columns, and a RFI covariate. Each column is an experimental unit. Those 24 experimental 
units are in one of the two lines: half of them is in HRFI (High Residual Feed Intake) line,
the other half is LRFI (Low Residual Feed Intake) line, denoted as line 1, and 2, correspondingly. The RFI value is the 
associated continuous covariate with each experimental unit. We want to know which 
genes are differentially expressed between two lines in the presence of the associated 
covariate RFI. 

\section{Model}

Let $y_{ijk}$ be the RNA expression level of gene $j\in \{1,\dots,J\}$ from experimential unit $k \in \{1, \dots, 12\}$ in group $i \in \{1,2\}$. Let $x_{ik}$ be the RFI value corresponding to the experimential unit $k$ in group $i$. Suppose the count data for each gene have a Poisson distribution  with the log link function of the mean as a linear combination of line effect and RFI covariate effects. In particular, 
\begin{align}\label{eq1}
& y_{ijk} \sim Poisson(\lambda_{ijk} )\notag\\
& log(\lambda_{ijk}) = \alpha_j + (-1)^{i}\tau_j + \beta_j x_{ik}\notag\\
& \alpha_j \sim N(0, 100^2)\notag\\
& \tau_j \sim \pi_\tau \delta_0 + (1-\pi_\tau) N(0, \sigma^2_\tau) \quad \mbox{ equivalently, } \tau_j = (1-\pi_{\tau_j})* N(0, \sigma^2_\tau), \pi_{\tau_j} \sim Bern(\pi_\tau)\notag\\
&\beta_j \sim \pi_\beta \delta_0 + (1-\pi_\beta)N(0, \sigma^2_\beta) 
\quad \mbox{ equivalently, } \beta_j = (1-\pi_{\beta_j})* N(0, \sigma^2_\beta), \pi_{\beta_j} \sim Bern(\pi_\beta)\\
& \pi_\tau \sim Beta(8, 1)\notag\\
& \pi_\beta \sim Beta(8, 1)\notag\\
& \sigma_\tau \sim Unif(0, 100)\notag\\
& \sigma_\beta \sim Unif(0, 100).\notag
\end{align}
here $\delta_0$ is the Dirac probability at $0$. Note that the specification of $\pi_\tau \sim Beta(8, 1), \pi_\beta \sim Beta(8, 1)$ is based on Section 2.2 of the paper "An Exploration of Aspects of Bayesian Multiple Testing" by JG Scott, JO Berger - Journal of Statistical Planning and Inference, 2006 - Elsevier    \url{http://www.sciencedirect.com.proxy.lib.iastate.edu/science/article/pii/S0378375805002156} where we \textit{believe} that the proportion of signals differentiating lines and covariate are small (around 5\%-20\%).  
Another option for the priors of parameters $\tau_j$ and $\beta_j$ can be 
horseshoe prior
\begin{align}\label{eq2}
& \tau_j \sim N(0, \sigma^2_{\tau_j}) \notag\\
& \sigma_{\tau_j} \sim Ca^+ (0, \sigma_\tau) \notag\\
& \sigma_\tau \sim Ca^+(0,1)\\
& \beta_j \sim N(0, \sigma^2_{\beta_j})\notag\\
& \sigma_{\beta_j} \sim Ca^+ (0, \sigma_\beta)\notag\\
& \sigma_\beta \sim Ca^+(0,1)\notag.
\end{align}

At the end, the inference goal is to estimate the posterior probability of signals (differential expression) $P(\tau_j \mbox{ is signal} |y)$. If $P(\tau_j \mbox{ is signal }|y) >0.5$, then the gene $j$ is called \textit{signal}, i.e., differentially expressed.

We propose two metrices to estimate the posterior probability of signals.
\begin{itemize}
\item Metric 1: We estimate the posterior probability of signal of gene $j$ 
for point mass mixture prior model (\ref{eq1}) by
\begin{equation}\label{ev1m}
P(\tau_j \mbox{ is signal }|y) = P(|\tau_j| >0 | y) \approx 
\frac {1}{M} \sum_{i=1}^M I(\pi_{\tau_j}^{(i)} = 0)
\end{equation}
where $(\pi_{\tau_j}^{(i)}, i = 1, \dots, M)$ is the posterior MCMC sample of $\pi_{\tau_j}$. 

On the other hand,  we estimate the posterior probability of signal of gene $j$  for the horseshoe prior model (\ref{eq2}) by 
\begin{equation}\label{ev1h}
P(\tau_j \mbox{ is signal }|y) \approx \frac {1}{M} \sum_{i=1}^M  \big(
1 - \frac{1}{1+\sigma_{\tau_j}^{2(i)}} \big)
\end{equation}
where $(\sigma_{\tau_j}^{2(i)}, i = 1, \dots, M)$ is the posterior MCMC sample of $\sigma_{\tau_j}^{2}$. 

This metric rule is a modified threshold rule motivated from section 3.4 Thresholding in the paper "The Horseshoe Estimator for Sparse Signals" by Carlos M. Carvalho and Nicholas G. Polson, Biometrika (2010), 97 ,2, pp. 465â€“480  \url{http://biomet.oxfordjournals.org/content/97/2/465.full.pdf}. Note that the paper use the normal distribution setting which is different from the Poission
distribution setting of this project. 
 
\item Metric 2: We  estimate the posterior probability of signal of gene $j$ for both models (\ref{eq1}) and (\ref{eq2}) by
 \begin{equation}\label{ev2}
 P(|\tau_j| > \varepsilon) \approx \frac{1}{M}\sum_{i = 1}^M I(|\tau_j^{(i)}| > \varepsilon)
 \end{equation}
 
 for given threshold $\varepsilon >0$.
 
 \end{itemize}

We will use these two metrics to evaluate performance of detecting signals 
in simulated dataset. Based on the simulation results, we will pick up the 
better model to analyze RFI data. For the purpose of this project, we will 
analyze first 200 genes of the original RNA-Seq dataset.

\section {Model in JAGS}
Below is the JAGS code for two models above. 
<<modelm_pointmass_mixture, tidy=FALSE, results='hide',echo=TRUE, message=FALSE,warning=FALSE>>=
library(rjags)
library(xtable)
#############modelm - using point mass mixture prior for signals###############
modelm <- "
model{
# likelihood 
for (i in 1:length(y)){
  y[i] ~ dpois(lambda[i])
  log(lambda[i]) <- alpha[gene[i]] + (-1)^line[i]*tau[gene[i]] + beta[gene[i]]*cov[i]   
}
# prior level 1
for (i in 1:ngene){
  alpha[i] ~ dnorm(0,1/10000)

  tau[i] <- (1-bintau[i])*normtau[i]
  bintau[i] ~ dbern(pitau)
  normtau[i] ~ dnorm(0,1/sigmatau^2)
  beta[i] <- (1-binbeta[i])*normbeta[i]
  binbeta[i] ~ dbern(pibeta)
  normbeta[i] ~ dnorm(0,1/sigmabeta^2)
  }
#prior level 2
pitau ~ dbeta(8,1)
pibeta ~ dbeta(8,1)
sigmatau ~ dunif(0,100)
sigmabeta ~ dunif(0,100)
}
"
@


<<horseshoe_prior, tidy=FALSE, results='hide',echo=TRUE, message=FALSE,warning=FALSE>>=
#########modelh - using horseshoe prior for the signals##############
modelh <- "
model{
# likelihood 
for (i in 1:length(y)){
  y[i] ~ dpois(lambda[i])
  log(lambda[i]) <- alpha[gene[i]] + (-1)^line[i]*tau[gene[i]] + beta[gene[i]]*cov[i]   
}
# prior level 1
for (j in 1:ngene){
  alpha[j] ~ dnorm(0,1/10000)
  tau[j] ~ dnorm(0, 1/sigmatauj[j]^2)
  sigmatauj[j] ~ dt(0, 1/sigmatau^2, 1) T(0,)
  beta[j] ~ dnorm(0, 1/sigmabetaj[j]^2)
  sigmabetaj[j] ~ dt(0, 1/sigmabeta^2, 1) T(0,)
}
# prior level 2
sigmatau ~ dt(0, 1, 1) T(0,)
sigmabeta ~ dt(0, 1, 1) T(0,)
}
"
@


\section{Evaluation models using simulation data}

We simulate data to evaluate the performance of the two models. For simplicity, 
we simulate a count table with dimension $100\times 24$ where 100 rows corresponding to 
100 genes, first 12 columns coresponding to line 1, the next 12 colums corresponding to 
line 2, as well as 24 covariate $x_{jk} \sim N(0,1)$. The element of count table at row $j$, colum $k$ is simulated from $Poisson(\lambda_{jk})$ where 
\begin{align*}
\lambda_{jk} &= \alpha_j -\tau_j + \beta_j x_{jk} ,\quad \mbox{for }\quad k = 1,\dots, 12\\
\lambda_{jk} &= \alpha_j +\tau_j + \beta_j x_{jk} ,\quad \mbox{for }\quad k = 13,\dots, 24\\
\alpha_j     & \sim N(3,2^2) \quad \mbox{for}\quad j = 1,\dots, 50\\
\tau_j       &= (1-Bern(0.8))*N(\mu_\tau,0.25^2) \quad \mu_\tau \in \{0.5, 1, 2\} \\
\beta_j      &=  (1-Bern(0.8))*N(\mu_\beta,0.25^2) \quad \mu_\beta \in \{0.5, 1, 2\}.
\end{align*}

<<simulation_data, tidy=FALSE,results='hide',echo=TRUE, message=FALSE,warning=FALSE>>=
library(reshape)
sim_data <- function(K, ngene, mualpha, sigmaalpha, 
                     pitau,mutau, sigmatau, pibeta,
                     mubeta, sigmabeta){
  # prior level 1
  x <- rnorm(2*K, 0,1)
  bintau <- rbinom(ngene,1,pitau)
  tau <-(1-bintau)*rnorm(ngene, mutau, sigmatau)
  beta <- (1-rbinom(ngene,1,pibeta))*rnorm(ngene, mubeta, sigmabeta)
  alpha <- rnorm(ngene, mualpha,sigmaalpha )
  lambda <- matrix(0, ncol = 2*K, nrow = ngene)
  count <- matrix(0, ncol = 2*K, nrow = ngene)
  for (j in 1:ngene){
  for (k in 1:K){
    lambda[j,k] <- exp(alpha[j] - tau[j] + beta[j]*x[k])
    lambda[j, k+K] <- exp(alpha[j] + tau[j] + beta[j]*x[k+K])
    count[j,k] <- rpois(1, lambda[j,k])
    count[j,k+K] <- rpois(1, lambda[j,k+K])
    }
  }
  melt_count <- melt(count)
  melt_count$line <- NULL
  melt_count$line[melt_count$X2%in%c(1:K)] <- 1
  melt_count$line[melt_count$X2%in%c((K+1):(2*K))] <- 2
  melt_count$cov <- NULL
  for(i in 1:(2*K)) melt_count$cov[melt_count$X2==i] <- x[i]
  dat <- list(y = melt_count$value, 
              gene = melt_count$X1, 
              line = melt_count$line, 
              cov = melt_count$cov, 
              ngene = ngene,
              tau = tau, 
              beta = beta, 
              alpha = alpha)
  return(dat)

}

@
\section{Running two JAGS models for simulation data}
Next, we run a MCMC using the point mass mixture model and horseshoe prior model. In the function below, we will calculate the estimated posterior probability of 
signal of $\tau_j$ for each $j$ based on two different evaluation rules \ref{ev1m}, \ref{ev2} for point mass mixture prior model \ref{eq1}, and based on two different evaluation rules \ref{ev1h}, \ref{ev2} for horseshoe prior model \ref{eq2}. 

<<run_mm_simulationdata,cache=TRUE, tidy=FALSE>>=
out <- function(K, ngene, mualpha, sigmaalpha, 
                     pitau,mutau, sigmatau, pibeta,
                     mubeta, sigmabeta, epstau, epsbeta){
  data <- sim_data(K, ngene, mualpha, sigmaalpha, 
                     pitau,mutau, sigmatau, pibeta,
                     mubeta, sigmabeta)
  
  mm <- jags.model(textConnection(modelm), data[1:5],n.chains = 1)
  resm <- coda.samples(mm, c("tau","alpha","beta",
                             "pitau","pibeta", 
                             "binbeta","bintau", 
                             "sigmatau","sigmabeta"), 2000) 
  
  mm_tau_est <- which(apply(resm[[1]][,paste("bintau[", 1:ngene,"]",sep ="")], 2, 
      function(x) mean(abs(1-x))) > 0.5)
  
  mm_tau_est_eps <- which(apply(resm[[1]][,paste("tau[", 1:ngene,"]",sep ="")], 2, 
      function(x) mean(abs(x)>epstau)) > 0.5)
  
  mm_tau_true <- which(data$tau!=0)
  mm_tau_correct <- sum(mm_tau_est%in%mm_tau_true)
  mm_tau_correct_eps <- sum(mm_tau_est_eps%in%mm_tau_true)
  
  mh <- jags.model(textConnection(modelh), data[1:5] ,n.chains = 1)
  resh <- coda.samples(mh, c("tau","alpha","beta",
                             "sigmatauj", "sigmabetaj",  
                             "sigmatau","sigmabeta"), 2000) 
  
  
  mh_tau_est <- which(apply(resh[[1]][,paste("sigmatauj[", 1:ngene,"]",sep ="")], 2, 
      function(x) mean(1-1/(x^2+1))) > 0.5)
  
  mh_tau_est_eps <- which(apply(resh[[1]][,paste("tau[", 1:ngene,"]",sep ="")], 2, 
      function(x) mean(abs(x)>epstau)) > 0.5)
  mh_tau_true <- which(data$tau!=0)
  mh_tau_correct <- sum(mh_tau_est%in%mh_tau_true)
  mh_tau_correct_eps <- sum(mh_tau_est_eps%in%mh_tau_true)
  
  return(c(   mm_tau_est = length(mm_tau_est), 
              mm_tau_correct_est = mm_tau_correct,
              mh_tau_est = length(mh_tau_est), 
              mh_tau_correct_est = mh_tau_correct,
              
              mm_tau_est_eps = length(mm_tau_est_eps), 
              mm_tau_correct_est_eps = mm_tau_correct_eps,
              mh_tau_est_eps = length(mh_tau_est_eps), 
              mh_tau_correct_est_eps = mh_tau_correct_eps,
              
              tau_true = length(mm_tau_true)
              ))
}

@


<<run_sim,cache=TRUE,message=FALSE,results='hide'>>=
K <- 12

ngene <- 100
# prior level 2
mualpha <- 3
sigmaalpha <- 2
pitau <-  0.8
mutau <- c(0.5,1,2)
sigmatau <- 0.25
pibeta <- 0.8
mubeta <- c(0.5,1,2)
sigmabeta  <- 0.25
epstau <- epsbeta <- 2*mutau/3
post_out <- array(0, dim = c(3,3,9))
for(i in 1:3){
  for (j in 1:3){
    post_out[i,j,] <- out(K, ngene, mualpha, sigmaalpha, 
                     pitau,mutau[i], sigmatau, pibeta,
                     mubeta[j] , sigmabeta, epstau[i], epsbeta[j])

  }
}

@
Results are below, where each 

<<results='asis', tidy = FALSE>>=
res <- cbind(post_out[1,1,],
            post_out[1,2,],
            post_out[1,3,],
            post_out[2,1,],
            post_out[2,2,],
            post_out[2,3,],
            post_out[3,1,],
            post_out[3,2,],
            post_out[3,3,])
colnames(res) <- c("(0.5,0.5)", "(0.5,1)", "(0.5,2)", 
              "(1,0.5)", "(1,1)", "(1,2)", 
              "(2,0.5)", "(2,1)", "(2,2)")


rownames(res) <- c("mm.est.DE.tau","mm.c.est.DE.tau",
                    "mh.est.DE.tau","mh.c.est.DE.tau",
                   "mm.est.DE.tau.eps","mm.c.est.DE.tau.eps",
                   "mh.est.DE.tau.eps","mh.c.est.DE.tau.eps",
                    "true.DE.tau")

@


Results of two models for estimating signal $\tau's$.

<<restau,results='asis',tidy=FALSE>>=
xtable(res, digit = 0, caption = "The meaning of rownames: mm stands for mixture 
       prior, mh stands for horseshoe prior.
       mm.est.DE.tau is the  number of estimated signal tau when using pointmass 
       mixture prior (mm).
       mm.c.est.DE.tau is the number of correctly estimated singal taus when using
       pointmass mixture prior.
       mm.est.DE.tau.eps is the number of estimated signal tau when using pointmass 
       mixture prior and the second metric (varepsilon).
       mm.c.est.DE.tau.eps is the number of correctly estimated 
       signal tau when using pointmass mixture prior and the second metric.
       true.DE.tau is the true number of signal taus (we know this because of
       simulation). 
       ")
@


Based on the above classification criterions,  the results show that the point mass mixture  model predict very well the signals coming from lines and covariate, and indeed it predicts better than the horseshoe prior does. When the signals are large, then the horse prior model performs well also. 



Moreover, by checking the plots of posterior densitiies of $\tau_j$, we also have the same conclusion. Below is  the plots obtained from an analysis based on a simulation data. 

<<plotsim,cache=TRUE,results='hide'>>=
K <- 12

ngene <- 5
# prior level 2
mualpha <- 3
sigmaalpha <- 2
pitau <-  0.8
mutau <- 1
sigmatau <- 0.25
pibeta <- 0.8
mubeta <- 1
sigmabeta  <- 0.25
data <- sim_data(K, ngene, mualpha, sigmaalpha, 
                     pitau,mutau, sigmatau, pibeta,
                     mubeta, sigmabeta)
  
  mm <- jags.model(textConnection(modelm), data[1:5],n.chains = 1)
  resm <- coda.samples(mm, c("tau","alpha","beta",
                             "pitau","pibeta", 
                             "binbeta","bintau", 
                             "sigmatau","sigmabeta"), 2000) 
mh <- jags.model(textConnection(modelh), data[1:5] ,n.chains = 1)
  resh <- coda.samples(mh, c("tau","alpha","beta",
                             "sigmatauj", "sigmabetaj",  
                             "sigmatau","sigmabeta"), 2000) 
@

Plot of posterior sample for $\tau_j$ when using point mass mixture model
<<plottau_mm,fig.pos='H'>>=
data$tau
plot(resm[, paste("tau[",1:ngene,"]",sep ="")])
@

Below is the dianogstic plots acf of the posterior samples
<<acf,fig.pos='H'>>=
par(mfrow = c(3,2))
acf(resm[[1]][,"tau[1]"], main = "tau1")
acf(resm[[1]][,"tau[2]"], main = "tau2")
acf(resm[[1]][,"tau[3]"], main = "tau3")
acf(resm[[1]][,"tau[4]"], main = "tau4")
acf(resm[[1]][,"tau[5]"], main = "tau5")
@



Plot of posterior sample for $\tau_j$ when using horseshoe prior model
<<plottau_mh,fig.pos='H'>>=
data$tau
plot(resh[, paste("tau[",1:ngene,"]",sep ="")])
@

Below is the dianogstic plots acf of the posterior samples
<<acfh,fig.pos='H'>>=
par(mfrow = c(3,2))
acf(resh[[1]][,"tau[1]"], main = "tau1")
acf(resh[[1]][,"tau[2]"], main = "tau2")
acf(resh[[1]][,"tau[3]"], main = "tau3")
acf(resh[[1]][,"tau[4]"], main = "tau4")
acf(resh[[1]][,"tau[5]"], main = "tau5")
@


\section{Analyze RFI data}

As mentioned before, we only analyze 200 genes in the RNASeq - RFI data set. Below is the analysis of the data using the point mass mixture prior Poission model.
<<realdata,cache = TRUE,results='hide'>>=
load("data.RData")
mm <- jags.model(textConnection(modelm), data,n.chains = 1)
resm <- coda.samples(mm, c("tau","beta", "alpha", "bintau", "binbeta"), 2000) 
@

Let's look at plots of some posterior samples of $\tau_i$
<<fig.pos='H'>>=
plot(resm[, paste("tau[",c(1:4),"]",sep ="")])


@

Number of signal genes if we choose the evaluation rule \ref{ev1m} 
<<tidy=FALSE>>=
mm_tau_est <- which(apply(resm[[1]][,paste("bintau[", 1:200,"]",sep ="")], 2, 
      function(x) mean(abs(1-x))) > 0.5)
length(mm_tau_est)

@

We can see that this number of signal genes seems to be not appropriate in reality. 

About the evaluation rule \ref{ev2}, we choose the threshold $\varepsilon$  to be 0.3, and by using this threshold, we obtain 13 most signal genes.  
Note that with different threshold values, we will have different set of signal genes. 
<<tidy=FALSE>>=
mm_tau_est_eps <- which(apply(resm[[1]][,paste("tau[", 1:200,"]",sep ="")], 2, 
      function(x) mean(abs(x)>0.3)) > 0.5)
length(mm_tau_est_eps)

@


List of genes that are differentially expressed according to the model \ref{eq1} 
and using the evaluation rule \ref{ev1m} is 
<<tidy=FALSE,message=FALSE>>=
mm_tau_est_eps 
load("data.RData")
str(data)
library(dplyr)
degene <- arrange(as.data.frame(cbind(data$line[data$gene ==mm_tau_est_eps[1]], 
      data$y[data$gene ==mm_tau_est_eps[1]], 
      data$y[data$gene ==mm_tau_est_eps[2]],
      data$y[data$gene ==mm_tau_est_eps[3]],
      data$y[data$gene ==mm_tau_est_eps[4]], 
      data$y[data$gene ==mm_tau_est_eps[5]],
      data$y[data$gene ==mm_tau_est_eps[6]],
      data$y[data$gene ==mm_tau_est_eps[7]], 
      data$y[data$gene ==mm_tau_est_eps[8]],
      data$y[data$gene ==mm_tau_est_eps[9]],
      data$y[data$gene ==mm_tau_est_eps[10]], 
      data$y[data$gene ==mm_tau_est_eps[11]],
      data$y[data$gene ==mm_tau_est_eps[12]],
      data$y[data$gene ==mm_tau_est_eps[13]])),V1)


colnames(degene) <- c("line", paste("gene",mm_tau_est_eps,sep = ""))
degene
@
\section{Conclusion}

In this project, we develop a full Bayesian model to analyzing RNASeq data. We consider two different prior specification. The first one is point mass mixture prior on the difference of expression data between two lines. The second ons is 
the horsehoe prior. We conduct a simulation study to evaluate the efficiency 
of these two specifications in prediting the true differences between two lines. 
The result turns out that under the point mass mixture prior model-based generated data, the mixture prior model outperforms the horseshoe prior. 
Finally, we adopt the point mass mixture prior model to analyze the RNASeq data and obtain a list of differential expressed genes (3 genes). Furthermore, the full RNASeq data consists of about 14000 genes, and it takes about 8 hours to run MCMC posterior samples on my computer, also the data file of posterior samples 
for the parameter ($\tau_j, \alpha_j, \beta_j$) is about 6GB, which is very big. 
One important point to note is that the  number of resulting differential expression genes (signal genes) will depend on the threshold value $\varepsilon$. Therefore, more work needs to be done to account for the false discovery rate
when changing the threshold value $\varepsilon$.

 

\end{document}