
\documentclass[12pt]{article}
% \usepackage[sc]{mathpazo}
% \usepackage[T1]{fontenc}
\usepackage{geometry}
\usepackage[toc,page]{appendix}
\usepackage{amsmath, amssymb, mathtools }
\usepackage{enumerate}
\usepackage{array}
\usepackage{fancyhdr}
\usepackage{verbatim}
\usepackage{color}
\usepackage{pstricks}
\usepackage{caption}
% \usepackage{longtable}
% \usepackage{fancyvrb}
% \usepackage{fancyhdr}
\usepackage{eqnarray}
%\pagestyle{fancy}
\usepackage{psfrag}
\usepackage{float}
\usepackage{epsfig,epsf}
\usepackage{pstricks}
\geometry{verbose,tmargin=2.5cm,bmargin=2.5cm,lmargin=2.5cm,rmargin=2.5cm}
\setcounter{secnumdepth}{2}
\setcounter{tocdepth}{2}
\usepackage{url}
\usepackage[unicode=true,pdfusetitle,
            bookmarks=true,bookmarksnumbered=true,bookmarksopen=true,bookmarksopenlevel=2,
            breaklinks=false,pdfborder={0 0 1},backref=false,colorlinks=false]
{hyperref}
\hypersetup{
  pdfstartview={XYZ null null 1}}
\usepackage{breakurl}
\begin{document}

<<setup, include=FALSE, cache=FALSE>>=
  # set global chunk options
opts_chunk$set(fig.path='figure/minimal-', fig.align='center', fig.show='hold')
options(replace.assign=TRUE,width=85)
set.seed(20140423)
@

\title{Final STAT544 Spring2014}

\author{Yet Tien Nguyen}

\maketitle

\section{Introduction}

In this project, we will analyze  RNA-Seq data from RFI (Residual Feed Intake) project
from ISU animal science research group. The data consists of a count table with ten thousand rows and 24 columns, and a RFI covariate. Each column is an experimental unit. Those 24 experimental 
units are in one of the two lines: half of them is in HRFI (High Residual Feed Intake) line,
the other half is LRFI (Low Residual Feed Intake) line, denoted as line 1, and 2, correspondingly. The RFI value is the 
associated continuous covariate with each experimental unit. We want to know which 
genes are differentially expressed between two lines in the presence of the associated 
covariate RFI. 

\section{Model}

Let $y_{ijk}$ be the RNA expression level of gene $j\in \{1,\dots,J\}$ from experimential unit $k \in \{1, \dots, 12\}$ in group $i \in \{1,2\}$. Let $x_{ik}$ be the RFI value corresponding to the experimential unit $k$ in group $i$. Suppose the count data for each gene have a Poisson distribution  with the log link function of the mean as a linear combination of line effect and RFI covariate effects. In particular, 
\begin{align}\label{eq1}
& y_{ijk} \sim Poisson(\lambda_{ijk} )\notag\\
& log(\lambda_{ijk}) = \alpha_j + (-1)^{i}\tau_j + \beta_j x_{ik}\notag\\
& \alpha_j \sim N(0, 100^2)\notag\\
& \tau_j \sim \pi_\tau \delta_0 + (1-\pi_\tau) N(0, \sigma^2_\tau) \quad \mbox{ equivalently, } \tau_j = (1-\pi_{\tau_j})* N(0, \sigma^2_\tau), \pi_{\tau_j} \sim Bern(\pi_\tau)\notag\\
&\beta_j \sim \pi_\beta \delta_0 + (1-\pi_\beta)N(0, \sigma^2_\beta) 
\quad \mbox{ equivalently, } \beta_j = (1-\pi_{\beta_j})* N(0, \sigma^2_\beta), \pi_{\beta_j} \sim Bern(\pi_\beta)\\
& \pi_\tau \sim Beta(8, 1)\notag\\
& \pi_\beta \sim Beta(8, 1)\notag\\
& \sigma_\tau \sim Unif(0, 100)\notag\\
& \sigma_\beta \sim Unif(0, 100).\notag
\end{align}
here $\delta_0$ is the Dirac probability at $0$. Note that the specification of $\pi_\tau \sim Beta(8, 1), \pi_\beta \sim Beta(8, 1)$ is based on Section 2.2 of the paper "An Exploration of Aspects of Bayesian Multiple Testing" by JG Scott, JO Berger - Journal of Statistical Planning and Inference, 2006 - Elsevier     where we \textit{believe} that the proportion of signals differentiating lines and covariate are small (around 1\%-20\%).  
Another option for the priors of parameters $\tau_j$ and $\beta_j$ can be 
horseshoe prior
\begin{align}\label{eq2}
& \tau_j \sim N(0, \sigma^2_{\tau_j}) \notag\\
& \sigma_{\tau_j} \sim Ca^+ (0, \sigma_\tau) \notag\\
& \sigma_\tau \sim Ca^+(0,1)\\
& \beta_j \sim N(0, \sigma^2_{\beta_j})\notag\\
& \sigma_{\beta_j} \sim Ca^+ (0, \sigma_\beta)\notag\\
& \sigma_\beta \sim Ca^+(0,1)\notag.
\end{align}

At the end, the inference goal is to estimate the posterior probability of signals (differential expression) $P(\tau_j \mbox{ is signal} |y)$. If $P(\tau_j \mbox{ is signal }|y) >0.5$, then the gene $j$ is called \textit{signal}, i.e., differentially expressed.

We propose two metrices to estimate the posterior probability of signals.
\begin{itemize}
\item Metric 1: We estimate the posterior probability of signal of gene $j$ 
for point mass mixture prior model (\ref{eq1}) by
\begin{equation}\label{ev1m}
P(\tau_j \mbox{ is signal }|y) = P(|\tau_j| >0 | y) \approx 
\frac {1}{M} \sum_{i=1}^M I(\pi_{\tau_j}^{(i)} = 0)
\end{equation}
where $(\pi_{\tau_j}^{(i)}, i = 1, \dots, M)$ is the posterior MCMC sample of $\pi_{\tau_j}$. 

On the other hand,  we estimate the posterior probability of signal of gene $j$  for the horseshoe prior model (\ref{eq2}) by 
\begin{equation}\label{ev1h}
P(\tau_j \mbox{ is signal }|y) \approx \frac {1}{M} \sum_{i=1}^M  \big(
1 - \frac{1}{1+\sigma_{\tau_j}^{2(i)}} \big)
\end{equation}
where $(\sigma_{\tau_j}^{2(i)}, i = 1, \dots, M)$ is the posterior MCMC sample of $\sigma_{\tau_j}^{2}$. 

This metric rule is a modified threshold rule motivated from section 3.4 Thresholding in the paper "The Horseshoe Estimator for Sparse Signals" by Carlos M. Carvalho and Nicholas G. Polson, Biometrika (2010), 97 ,2, pp. 465â€“480. Note that the paper use the normal distribution setting which is different from the Poission
distribution setting of this project. 
 
\item Metric 2: We  estimate the posterior probability of signal of gene $j$ for both models (\ref{eq1}) and (\ref{eq2}) by
 \begin{equation}\label{ev2}
 P(|\tau_j| > \varepsilon) \approx \frac{1}{M}\sum_{i = 1}^M I(|\tau_j^{(i)}| > \varepsilon)
 \end{equation}
 
 for given threshold $\varepsilon >0$.
 
 \end{itemize}

We will use these two metrics to evaluate performance of detecting signals 
in simulated dataset. Based on the simulation results, we will pick up the 
better model to analyze RFI data. For the purpose of this project, we will 
analyze first 200 genes of the original RNA-Seq dataset.

% \section {Model in JAGS}
% Below is the JAGS code for two models above. 
<<modelm_pointmass_mixture, tidy=FALSE, results='hide',echo=FALSE, message=FALSE,warning=FALSE>>=
library(rjags)
library(xtable)
#############modelm - using point mass mixture prior for signals###############
modelm <- "
model{
# likelihood 
for (i in 1:length(y)){
  y[i] ~ dpois(lambda[i])
  log(lambda[i]) <- alpha[gene[i]] + (-1)^line[i]*tau[gene[i]] + beta[gene[i]]*cov[i]   
}
# prior level 1
for (i in 1:ngene){
  alpha[i] ~ dnorm(0,1/10000)

  tau[i] <- (1-bintau[i])*normtau[i]
  bintau[i] ~ dbern(pitau)
  normtau[i] ~ dnorm(0,1/sigmatau^2)
  beta[i] <- (1-binbeta[i])*normbeta[i]
  binbeta[i] ~ dbern(pibeta)
  normbeta[i] ~ dnorm(0,1/sigmabeta^2)
  }
#prior level 2
pitau ~ dbeta(8,1)
pibeta ~ dbeta(8,1)
sigmatau ~ dunif(0,100)
sigmabeta ~ dunif(0,100)
}
"
@


<<horseshoe_prior, tidy=FALSE, results='hide',echo=FALSE, message=FALSE,warning=FALSE>>=
#########modelh - using horseshoe prior for the signals##############
modelh <- "
model{
# likelihood 
for (i in 1:length(y)){
  y[i] ~ dpois(lambda[i])
  log(lambda[i]) <- alpha[gene[i]] + (-1)^line[i]*tau[gene[i]] + beta[gene[i]]*cov[i]   
}
# prior level 1
for (j in 1:ngene){
  alpha[j] ~ dnorm(0,1/10000)
  tau[j] ~ dnorm(0, 1/sigmatauj[j]^2)
  sigmatauj[j] ~ dt(0, 1/sigmatau^2, 1) T(0,)
  beta[j] ~ dnorm(0, 1/sigmabetaj[j]^2)
  sigmabetaj[j] ~ dt(0, 1/sigmabeta^2, 1) T(0,)
}
# prior level 2
sigmatau ~ dt(0, 1, 1) T(0,)
sigmabeta ~ dt(0, 1, 1) T(0,)
}
"
@


\section{Evaluation two models using simulation data}

We simulate data to evaluate the performance of the two models in detecting true signals. For simplicity, 
we simulate a count table with dimension $100\times 24$ where each row corresponding to 
one gene, first 12 columns corresponding to line 1, the next 12 colums corresponding to 
line 2. Also, we simulate 24 covariates $x_{k} \sim N(0,1)$ for $k = 1,\dots, 24$. The $(j,k)-$ element of the count table is simulated from $Poisson(\lambda_{jk})$ distribution, where 
\begin{align}
\lambda_{jk} &= \alpha_j -\tau_j + \beta_j x_{k} ,\quad \mbox{for }\quad k = 1,\dots, 12\notag\\
\lambda_{jk} &= \alpha_j +\tau_j + \beta_j x_{k} ,\quad \mbox{for }\quad k = 13,\dots, 24 \notag\\
\alpha_j     & \sim N(3,2^2) \quad \mbox{for}\quad j = 1,\dots, 50 \label{sim}\\
\tau_j       &= (1-Bern(0.8))*N(\mu_\tau,0.25^2) \quad \mu_\tau \in \{0.5, 1, 2\} \notag\\
\beta_j      &=  (1-Bern(0.8))*N(\mu_\beta,0.25^2) \quad \mu_\beta \in \{0.5, 1, 2\}\notag.
\end{align}
In summary, we have total $3\times 3 = 9$ different simulation scenarios. Each simulation scenario 
corresponds to one pairs of value 
$$
(\mu_\tau, \mu_\beta) \in \{(0.5, 0.5), (0.5, 1), (0.5, 2), (1, 0.5), (1, 1), (1, 2), (2, 0.5), (2, 1), (2, 2) \}.
$$

<<simulation_data, tidy=FALSE,results='hide',echo=FALSE, message=FALSE,warning=FALSE>>=
library(reshape)
sim_data <- function(K, ngene, mualpha, sigmaalpha, 
                     pitau,mutau, sigmatau, pibeta,
                     mubeta, sigmabeta){
  # prior level 1
  x <- rnorm(2*K, 0,1)
  bintau <- rbinom(ngene,1,pitau)
  tau <-(1-bintau)*rnorm(ngene, mutau, sigmatau)
  beta <- (1-rbinom(ngene,1,pibeta))*rnorm(ngene, mubeta, sigmabeta)
  alpha <- rnorm(ngene, mualpha,sigmaalpha )
  lambda <- matrix(0, ncol = 2*K, nrow = ngene)
  count <- matrix(0, ncol = 2*K, nrow = ngene)
  for (j in 1:ngene){
  for (k in 1:K){
    lambda[j,k] <- exp(alpha[j] - tau[j] + beta[j]*x[k])
    lambda[j, k+K] <- exp(alpha[j] + tau[j] + beta[j]*x[k+K])
    count[j,k] <- rpois(1, lambda[j,k])
    count[j,k+K] <- rpois(1, lambda[j,k+K])
    }
  }
  melt_count <- melt(count)
  melt_count$line <- NULL
  melt_count$line[melt_count$X2%in%c(1:K)] <- 1
  melt_count$line[melt_count$X2%in%c((K+1):(2*K))] <- 2
  melt_count$cov <- NULL
  for(i in 1:(2*K)) melt_count$cov[melt_count$X2==i] <- x[i]
  dat <- list(y = melt_count$value, 
              gene = melt_count$X1, 
              line = melt_count$line, 
              cov = melt_count$cov, 
              ngene = ngene,
              tau = tau, 
              beta = beta, 
              alpha = alpha)
  return(dat)

}

@
% \section{Running two JAGS models for simulation data}
For each simulation scenario, we simultaneously run a MCMC  for the model (\ref{eq1}) which is the point mass mixture prior model and the model (\ref{eq2}) which is the horseshoe prior model. Then, we calculate the estimated posterior probability of 
signal of $\tau_j$ for each $j$ based on two different evaluation metrices 
introduced in Section 2. In particular, with respect to metric 2, we use threshold $\varepsilon = 2\mu_\tau/3$ where $\mu_\tau$ is the corresponding 
$\mu_\tau$ of the simulation scenario. The ability to detect true signals of each model with specific metric is summarized in Table \ref{simtable}.

\begin{table}[ht]
\centering
\begin{tabular}{rrrrrrrrrr}
\hline
& (0.5,0.5) & (0.5,1) & (0.5,2) & (1,0.5) & (1,1) & (1,2) & (2,0.5) & (2,1) & (2,2) \\
\hline
(\ref{eq1})(\ref{ev1m}) & 19(16) & 20(20) & 20(20) & 26(26) & 28(27) & 24(24) & 19(19) & 16(16) & 17(17) \\
% mm.c.est.DE.tau & 16 & 20 & 20 & 26 & 27 & 24 & 19 & 16 & 17 \\
(\ref{eq2})(\ref{ev1h}) & 2(2) & 0(0) & 0(0) & 6(6) & 9(9) & 7(7) & 19(19) & 15(15) & 17(17) \\
% mh.c.est.DE.tau & 2 & 0 & 0 & 6 & 9 & 7 & 19 & 15 & 17 \\
(\ref{eq1})(\ref{ev2}) & 15(14) & 14(14) & 15(15) & 23(23) & 23(23) & 20(20) & 19(19) & 15(15) & 17(17) \\
% mm.c.est.DE.tau.eps & 14 & 14 & 15 & 23 & 23 & 20 & 19 & 15 & 17 \\
(\ref{eq2})(\ref{ev1m}) & 12(12) & 12(12) & 14(14) & 21(21) & 23(23) & 20(20) & 19(19) & 15(15) & 17(17) \\
% mh.c.est.DE.tau.eps & 12 & 12 & 14 & 21 & 23 & 20 & 19 & 15 & 17 \\
true signals & 20 & 22 & 22 & 26 & 27 & 25 & 19 & 16 & 17 \\
\hline
\end{tabular}
\caption{Results of detecting signals of two models (\ref{eq1}) and (\ref{eq2})
in 9 simulation scenarios. 
}
\label{simtable}
\end{table}

The explanation of the Table \ref{simtable} is as below. Each column  is  one simulation scenario corresponding to the value of $(\mu_\tau, \mu_\beta)$. Each row is the specification of  the model and metric. Each element of the table indicates the number of detected signals and the number of correctly detected signals by the model and metric specified by its row name.  For example, the element 19(16) at the first row "(\ref{eq1})(\ref{ev1m})" and the first column "(0.5, 0.5)" means that: for the simulation scenario (\ref{sim}),  model $(\ref{eq1})$ with metric $\ref{ev1m}$ detects 19 signals, 16 signals of which are correct signals, and there is total 20 true signals (the number at the last row in the first column). 

<<run_mm_simulationdata,cache=TRUE, tidy=FALSE,echo=FALSE>>=
out <- function(K, ngene, mualpha, sigmaalpha, 
                     pitau,mutau, sigmatau, pibeta,
                     mubeta, sigmabeta, epstau, epsbeta){
  data <- sim_data(K, ngene, mualpha, sigmaalpha, 
                     pitau,mutau, sigmatau, pibeta,
                     mubeta, sigmabeta)
  
  mm <- jags.model(textConnection(modelm), data[1:5],n.chains = 1)
  resm <- coda.samples(mm, c("tau","alpha","beta",
                             "pitau","pibeta", 
                             "binbeta","bintau", 
                             "sigmatau","sigmabeta"), 2000) 
  
  mm_tau_est <- which(apply(resm[[1]][,paste("bintau[", 1:ngene,"]",sep ="")], 2, 
      function(x) mean(abs(1-x))) > 0.5)
  
  mm_tau_est_eps <- which(apply(resm[[1]][,paste("tau[", 1:ngene,"]",sep ="")], 2, 
      function(x) mean(abs(x)>epstau)) > 0.5)
  
  mm_tau_true <- which(data$tau!=0)
  mm_tau_correct <- sum(mm_tau_est%in%mm_tau_true)
  mm_tau_correct_eps <- sum(mm_tau_est_eps%in%mm_tau_true)
  
  mh <- jags.model(textConnection(modelh), data[1:5] ,n.chains = 1)
  resh <- coda.samples(mh, c("tau","alpha","beta",
                             "sigmatauj", "sigmabetaj",  
                             "sigmatau","sigmabeta"), 2000) 
  
  
  mh_tau_est <- which(apply(resh[[1]][,paste("sigmatauj[", 1:ngene,"]",sep ="")], 2, 
      function(x) mean(1-1/(x^2+1))) > 0.5)
  
  mh_tau_est_eps <- which(apply(resh[[1]][,paste("tau[", 1:ngene,"]",sep ="")], 2, 
      function(x) mean(abs(x)>epstau)) > 0.5)
  mh_tau_true <- which(data$tau!=0)
  mh_tau_correct <- sum(mh_tau_est%in%mh_tau_true)
  mh_tau_correct_eps <- sum(mh_tau_est_eps%in%mh_tau_true)
  
  return(c(   mm_tau_est = length(mm_tau_est), 
              mm_tau_correct_est = mm_tau_correct,
              mh_tau_est = length(mh_tau_est), 
              mh_tau_correct_est = mh_tau_correct,
              
              mm_tau_est_eps = length(mm_tau_est_eps), 
              mm_tau_correct_est_eps = mm_tau_correct_eps,
              mh_tau_est_eps = length(mh_tau_est_eps), 
              mh_tau_correct_est_eps = mh_tau_correct_eps,
              
              tau_true = length(mm_tau_true)
              ))
}

@


<<run_sim,cache=TRUE,message=FALSE,results='hide',echo=FALSE>>=
K <- 12

ngene <- 100
# prior level 2
mualpha <- 3
sigmaalpha <- 2
pitau <-  0.8
mutau <- c(0.5,1,2)
sigmatau <- 0.25
pibeta <- 0.8
mubeta <- c(0.5,1,2)
sigmabeta  <- 0.25
epstau <- epsbeta <- 2*mutau/3
post_out <- array(0, dim = c(3,3,9))
for(i in 1:3){
  for (j in 1:3){
    post_out[i,j,] <- out(K, ngene, mualpha, sigmaalpha, 
                     pitau,mutau[i], sigmatau, pibeta,
                     mubeta[j] , sigmabeta, epstau[i], epsbeta[j])

  }
}

@
% Results are below, where each 
% 
% <<results='asis', tidy = FALSE,echo=FALSE>>=
% res <- cbind(post_out[1,1,],
%             post_out[1,2,],
%             post_out[1,3,],
%             post_out[2,1,],
%             post_out[2,2,],
%             post_out[2,3,],
%             post_out[3,1,],
%             post_out[3,2,],
%             post_out[3,3,])
% colnames(res) <- c("$\\alpha_1$ (0.5,0.5)", "(0.5,1)", "(0.5,2)", 
%               "(1,0.5)", "(1,1)", "(1,2)", 
%               "(2,0.5)", "(2,1)", "(2,2)")
% 
% 
% rownames(res) <- c("$\\alpha_1$","mm.c.est.DE.tau",
%                     "mh.est.DE.tau","mh.c.est.DE.tau",
%                    "mm.est.DE.tau.eps","mm.c.est.DE.tau.eps",
%                    "mh.est.DE.tau.eps","mh.c.est.DE.tau.eps",
%                     "true.DE.tau")
% 
% @
% 
% <<results='asis'>>=
% library(xtable)
% adf.results<-matrix(0,ncol=6,nrow=4)
% colnames(adf.results) <- c(" ", "$m^r_t$", "$\\delta p_t$","$R^r_t$", "$R^b_t$", "$y^r_t$")
% print(xtable(adf.results, caption = "xx $\\alpha_1$"),sanitize.text.function=function(x){x})
% @

%Results of two models for estimating signal $\tau's$.
<<restau2, results='hide',echo=FALSE>>=
library(xtable)
res <- cbind(post_out[1,1,],
            post_out[1,2,],
            post_out[1,3,],
            post_out[2,1,],
            post_out[2,2,],
            post_out[2,3,],
            post_out[3,1,],
            post_out[3,2,],
            post_out[3,3,])
class(res)
colnames(res) <- c("$\\alpha_1$ (0.5,0.5)", "(0.5,1)", "(0.5,2)", 
              "(1,0.5)", "(1,1)", "(1,2)", 
              "(2,0.5)", "(2,1)", "(2,2)")


rownames(res) <- c("$\\alpha_1$","mm.c.est.DE.tau",
                    "mh.est.DE.tau","mh.c.est.DE.tau",
                   "mm.est.DE.tau.eps","mm.c.est.DE.tau.eps",
                   "mh.est.DE.tau.eps","mh.c.est.DE.tau.eps",
                    "true.DE.tau")

print(xtable(res, digit = 0, caption = "The meaning of rownames: mm stands for mixture 
       prior, mh stands for horseshoe prior.$\\alpha_1$
       mm.est.DE.tau is the  number of estimated signal tau when using pointmass 
       mixture prior (mm).
       mm.c.est.DE.tau is the number of correctly estimated singal taus when using
       pointmass mixture prior.
       mm.est.DE.tau.eps is the number of estimated signal tau when using pointmass 
       mixture prior and the second metric (varepsilon).
       mm.c.est.DE.tau.eps is the number of correctly estimated 
       signal tau when using pointmass mixture prior and the second metric.
       true.DE.tau is the true number of signal taus (we know this because of
       simulation). 
       "),sanitize.text.function=function(x){x})
@

<<restau,results='hide',echo=FALSE>>=
library(xtable)
res <- cbind(post_out[1,1,],
            post_out[1,2,],
            post_out[1,3,],
            post_out[2,1,],
            post_out[2,2,],
            post_out[2,3,],
            post_out[3,1,],
            post_out[3,2,],
            post_out[3,3,])
class(res)
colnames(res) <- c("$\\alpha_1$ (0.5,0.5)", "(0.5,1)", "(0.5,2)", 
              "(1,0.5)", "(1,1)", "(1,2)", 
              "(2,0.5)", "(2,1)", "(2,2)")


rownames(res) <- c("$\\alpha_1$","mm.c.est.DE.tau",
                    "mh.est.DE.tau","mh.c.est.DE.tau",
                   "mm.est.DE.tau.eps","mm.c.est.DE.tau.eps",
                   "mh.est.DE.tau.eps","mh.c.est.DE.tau.eps",
                    "true.DE.tau")

print(xtable(res, digit = 0, caption = "The meaning of rownames: mm stands for mixture 
       prior, mh stands for horseshoe prior.$\\alpha_1$
       mm.est.DE.tau is the  number of estimated signal tau when using pointmass 
       mixture prior (mm).
       mm.c.est.DE.tau is the number of correctly estimated singal taus when using
       pointmass mixture prior.
       mm.est.DE.tau.eps is the number of estimated signal tau when using pointmass 
       mixture prior and the second metric (varepsilon).
       mm.c.est.DE.tau.eps is the number of correctly estimated 
       signal tau when using pointmass mixture prior and the second metric.
       true.DE.tau is the true number of signal taus (we know this because of
       simulation). 
       "),sanitize.text.function=function(x){x})
@


Table \ref{simtable} shows that the point mass mixture prior  model (\ref{eq1}) predicts very well the true signals between two lines, and indeed it predicts better than the horseshoe prior model (\ref{eq2}) does. However, when the signals are large, the horseshoe prior model (\ref{eq2}) performs well also. 
Furthermore, by checking the plots of posterior densitiies of $\tau_j$, we also have the same conclusion. The Figures \ref{fig:plottau_mm}, \ref{fig:acf},
\ref{fig:plottau_mh}, \ref{fig:acfh} are the plots obtained from an analysis based on a simulation scenario (\ref{sim})  with $(\mu_\tau, \mu_\beta) = (1,1)$ and  4 genes $j = 1,\dots, 4$, the simulated parameters $\tau_3 = 1.49$, and $\tau_j =0$ for all $j=1,2,4$. 

<<plotsim,cache=TRUE,results='hide',echo=FALSE>>=
K <- 12

ngene <- 4
# prior level 2
mualpha <- 3
sigmaalpha <- 2
pitau <-  0.8
mutau <- 1
sigmatau <- 0.25
pibeta <- 0.8
mubeta <- 1
sigmabeta  <- 0.25
data <- sim_data(K, ngene, mualpha, sigmaalpha, 
                     pitau,mutau, sigmatau, pibeta,
                     mubeta, sigmabeta)
  
  mm <- jags.model(textConnection(modelm), data[1:5],n.chains = 1)
  resm <- coda.samples(mm, c("tau","alpha","beta",
                             "pitau","pibeta", 
                             "binbeta","bintau", 
                             "sigmatau","sigmabeta"), 2000) 
mh <- jags.model(textConnection(modelh), data[1:5] ,n.chains = 1)
  resh <- coda.samples(mh, c("tau","alpha","beta",
                             "sigmatauj", "sigmabetaj",  
                             "sigmatau","sigmabeta"), 2000) 
@


<<plottau_mm,echo=FALSE,fig.align='center',fig.cap='Posterior samples of $\\tau_j, j = 1,\\dots, 4$ for the point mass mixture prior model (\\ref{eq1}).',fig.pos='H'>>=
plot(resm[, paste("tau[",1:4,"]",sep ="")])
@

<<acf,echo=FALSE,fig.cap='The dianogstic plots acf of the posterior MCMC samples of $\\tau_j, j =1,\\dots,4$ under the point mass mixture prior model (\\ref{eq1}).',fig.pos='H'>>=
par(mfrow = c(2,2))
acf(resm[[1]][,"tau[1]"], main = "tau1")
acf(resm[[1]][,"tau[2]"], main = "tau2")
acf(resm[[1]][,"tau[3]"], main = "tau3")
acf(resm[[1]][,"tau[4]"], main = "tau4")
@




<<plottau_mh,echo=FALSE,fig.cap='Posterior samples of $\\tau_j, j = 1,\\dots, 4$ for the horseshoe prior model (\\ref{eq2}).',fig.pos='H'>>=
#data$tau
plot(resh[, paste("tau[",1:ngene,"]",sep ="")])
@

<<acfh,fig.cap='The dianogstic plots acf of the posterior MCMC samples of $\\tau_j, j =1,\\dots,4$ under the horseshoe prior model (\\ref{eq2}).',echo=FALSE,fig.pos='H'>>=
par(mfrow = c(2,2))
acf(resh[[1]][,"tau[1]"], main = "tau1")
acf(resh[[1]][,"tau[2]"], main = "tau2")
acf(resh[[1]][,"tau[3]"], main = "tau3")
acf(resh[[1]][,"tau[4]"], main = "tau4")

@

\section{Analyze RFI data}

As mentioned above, we only analyze 200 genes in the RNASeq - RFI data set for the simplicity. Based on the simulation results, we will use the point mass mixture prior Poission model (\ref{eq1}) with two metrics \eqref{ev1m} and \eqref{ev2} to see how they perform in analyzing this real dataset. As it turns out, the model \eqref{eq1} with metric \eqref{ev1m} gives 184 signals which is a very high number and is not appropriate in reality that we \textit{believe} the signals are sparse. On the other hand, the model \eqref{eq1} with metric \eqref{ev2} and $\varepsilon = 0.5$ gives 3 signals

<<realdata,cache = TRUE,results='hide',echo=FALSE>>=
load("data.RData")
mm <- jags.model(textConnection(modelm), data,n.chains = 1)
resm <- coda.samples(mm, c("tau","beta", "alpha", "bintau", "binbeta"), 2000) 
@

<<echo=FALSE,fig.cap='Posterior samples of $\\tau_j, j = 1,\\dots, 4$ for the real data RNA-Seq under the point mass mixture prior model (\\ref{eq1}).',fig.pos='H'>>=
plot(resm[, paste("tau[",c(1:4),"]",sep ="")])


@


<<acfrna,fig.cap='The dianogstic plots acf of the posterior MCMC samples of $\\tau_j, j =1,\\dots,4$ for the real RNA-Seq data under the point mass mixture prior model (\\ref{eq1}).',echo=FALSE,fig.pos='H'>>=
par(mfrow = c(2,2))
acf(resm[[1]][,"tau[1]"], main = "tau1")
acf(resm[[1]][,"tau[2]"], main = "tau2")
acf(resm[[1]][,"tau[3]"], main = "tau3")
acf(resm[[1]][,"tau[4]"], main = "tau4")

@


<<tidy=FALSE,echo=FALSE,results='hide'>>=
mm_tau_est <- which(apply(resm[[1]][,paste("bintau[", 1:200,"]",sep ="")], 2, 
      function(x) mean(abs(1-x))) > 0.5)
length(mm_tau_est)

@

<<tidy=FALSE,results='hide',echo=FALSE>>=
mm_tau_est_eps <- which(apply(resm[[1]][,paste("tau[", 1:200,"]",sep ="")], 2, 
      function(x) mean(abs(x)>0.5)) > 0.5)
length(mm_tau_est_eps)

@


% List of genes that are differentially expressed according to the model \ref{eq1} 
% and using the evaluation rule \ref{ev1m} is 
<<tidy=FALSE,message=FALSE,echo=FALSE>>=
#mm_tau_est_eps 
load("data.RData")
#str(data)
library(dplyr)
# degene <- arrange(as.data.frame(cbind(data$line[data$gene ==mm_tau_est_eps[1]], 
#       data$y[data$gene ==mm_tau_est_eps[1]], 
#       data$y[data$gene ==mm_tau_est_eps[2]],
#       data$y[data$gene ==mm_tau_est_eps[3]],
#       data$y[data$gene ==mm_tau_est_eps[4]], 
#       data$y[data$gene ==mm_tau_est_eps[5]],
#       data$y[data$gene ==mm_tau_est_eps[6]],
#       data$y[data$gene ==mm_tau_est_eps[7]], 
#       data$y[data$gene ==mm_tau_est_eps[8]],
#       data$y[data$gene ==mm_tau_est_eps[9]],
#       data$y[data$gene ==mm_tau_est_eps[10]], 
#       data$y[data$gene ==mm_tau_est_eps[11]],
#       data$y[data$gene ==mm_tau_est_eps[12]],
#       data$y[data$gene ==mm_tau_est_eps[13]])),V1)
# 

degene <- arrange(as.data.frame(cbind(data$line[data$gene ==mm_tau_est_eps[1]], 
      data$y[data$gene ==mm_tau_est_eps[1]], 
      data$y[data$gene ==mm_tau_est_eps[2]],
      data$y[data$gene ==mm_tau_est_eps[3]])),V1)

colnames(degene) <- c("line", paste("gene",mm_tau_est_eps,sep = ""))
degene
@
\section{Conclusion}

In this project, we develop a full Bayesian approach to analyze RNASeq data. We consider two models with different prior specifications. The first one is point mass mixture prior model \eqref{eq1}. The second ons is 
the horsehoe prior model \eqref{eq2}. We conduct a simulation study to evaluate the efficiency 
of  these models in prediting the true differences between two lines. 
The simulation results  suggest that the point mass mixture prior model \eqref{eq1} outperforms the horseshoe prior model \eqref{eq2} for the simulation scenarios \eqref{sim}. 
Then, we use the point mass mixture prior model \eqref{eq1} to analyze the RNASeq data and obtain a list of 3 signal genes (differentiallly expressed genes) in total 200 genes. However, the full RNASeq data consists of about 14000 genes, and it takes about 8 hours to run MCMC posterior samples on my computer, also the size of posterior samples 
for the parameters ($\tau_j, \alpha_j, \beta_j$) is about 6GB, which is very big. 
One important point to note is that  using metric \eqref{ev2}, the  number of signal genes depends on the threshold value $\varepsilon$. Therefore, more work needs to be done to account for the false discovery rate
when changing the threshold value $\varepsilon$.

\begin{appendices}
All plots of the projects are below.
\end{appendices}
\end{document}